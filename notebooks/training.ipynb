{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtxKg16t3hEv",
        "outputId": "e1c8c1cb-2612-4018-9400-9c717aad1a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[K     |████████████████████████████████| 81 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 113 kB 84.1 MB/s \n",
            "\u001b[?25h  Building wheel for importRosbag (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 92 kB 597 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "!pip install tonic --quiet\n",
        "!pip install snntorch --quiet\n",
        "\n",
        "import gc\n",
        "import os\n",
        "import ast\n",
        "import csv\n",
        "import torch\n",
        "import tonic\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import tonic.transforms as transforms\n",
        "from snntorch import utils\n",
        "from snntorch import surrogate \n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "SRC = \"/content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/\"\n",
        "\n",
        "# List of .csv files with event data\n",
        "csv_files = [SRC + 'GT_HW1_1_DROPPED.csv', SRC + 'GT_HW1_3_DROPPED.csv', SRC + 'GT_HW1_4_DROPPED.csv', SRC + 'GT_HW2_1_DROPPED.csv', \n",
        "             SRC + 'GT_HW2_2_DROPPED.csv', SRC + 'GT_HW2_3_DROPPED.csv', SRC + 'GT_HW2_4_DROPPED.csv', SRC + 'GT_HW2_5_DROPPED.csv', \n",
        "             SRC + 'GT_HW2_6_DROPPED.csv', SRC + 'GT_LAMBDA_1_DROPPED.csv', SRC + 'GT_LAMBDA_2_DROPPED.csv', SRC + 'GT_LAMBDA_3_DROPPED.csv', \n",
        "             SRC + 'GT_LAMBDA_4_DROPPED.csv', SRC + 'GT_LAMBDA_5_DROPPED.csv', SRC + 'GT_LAMBDA_6_DROPPED.csv', SRC + 'GT_LAMBDA_7_DROPPED.csv', \n",
        "             SRC + 'GT_LAMBDA_8_DROPPED.csv', SRC + 'GT_BOX1_DROPPED.csv', SRC + 'GT_BOX2_DROPPED.csv', SRC + 'GT_FLOOR_DROPPED.csv']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy3tak9HBEU_",
        "outputId": "b5ec0ca4-4b25-4ab5-d032-ecd44f36396e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr  1 18:41:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Your runtime has 54.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAt-RYq_8gNq",
        "outputId": "de5a3745-ceba-4e10-c2a6-d7acf2c817f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW1_1_DROPPED.csv\n",
            "Number of data points:  899\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW1_3_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW1_4_DROPPED.csv\n",
            "Number of data points:  238\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_1_DROPPED.csv\n",
            "Number of data points:  899\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_2_DROPPED.csv\n",
            "Number of data points:  897\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_3_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_4_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_5_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_HW2_6_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_1_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_2_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_3_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_4_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_5_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_6_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_7_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_LAMBDA_8_DROPPED.csv\n",
            "Number of data points:  898\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_BOX1_DROPPED.csv\n",
            "Number of data points:  2137\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_BOX2_DROPPED.csv\n",
            "Number of data points:  6130\n",
            "Read:  /content/drive/Shareddrives/Shilpa_Thesis/processed_data/dropped/GT_FLOOR_DROPPED.csv\n",
            "Number of data points:  2058\n",
            "Length of all data points:  24932\n"
          ]
        }
      ],
      "source": [
        "df_list = []\n",
        "for file in csv_files:\n",
        "  # Drop unecessary columns when reading in the dataframes\n",
        "  df = pd.read_csv(file, index_col = 0).reset_index(drop = True)\n",
        "  print(\"Read: \", file)\n",
        "  print(\"Number of data points: \", len(df))\n",
        "  del df['index']\n",
        "  df_list.append(df)\n",
        "concat_df = pd.concat(df_list).reset_index(drop = True)\n",
        "print(\"Length of all data points: \", len(concat_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XmD4wge9E8y",
        "outputId": "6f722ebc-5a5e-471d-95f7-ad8cedc669fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size:  14959\n",
            "Validation dataset size:  6233\n",
            "Test dataset size:  3740\n"
          ]
        }
      ],
      "source": [
        "# Shuffle the dataframe rows and reset the index before training/validation/test split\n",
        "shuffled_df = concat_df.sample(frac = 1).reset_index(drop = True)\n",
        "\n",
        "# Split the concatenated dataframe into training and test subsets\n",
        "train_df, validation_df = train_test_split(concat_df, test_size = 0.25)\n",
        "train_df, test_df = train_test_split(train_df, test_size = 0.20)\n",
        "print(\"Training dataset size: \", len(train_df))\n",
        "print(\"Validation dataset size: \", len(validation_df))\n",
        "print(\"Test dataset size: \", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p6xwY28-4Nzy"
      },
      "outputs": [],
      "source": [
        "class SyntheticRecording(tonic.Dataset):\n",
        "  \"\"\"\n",
        "      Synthetic event camera recordings dataset.\n",
        "  \"\"\"\n",
        "  def __init__(self, df):\n",
        "    super(SyntheticRecording, self).__init__()\n",
        "    self.df = df.reset_index(drop = True) # Address index out of order issue\n",
        "    self.events = self.df['Events'] # Select only last column of dataframe\n",
        "    self.target = self.df[['Vel_x', 'Vel_y', 'Vel_z']] # Select every column except last column of dataframe\n",
        "    self.sensor_size = (1920, 1080, 2)\n",
        "    # Denoise removes isolated, one-off events\n",
        "    self.frame_transform = transforms.Compose([transforms.Denoise(filter_time = 1000000),\n",
        "                                               transforms.ToFrame(sensor_size = (1920, 1080, 2), n_event_bins = 5)]) \n",
        "    \n",
        "  \"\"\"\n",
        "      Retrieve the index i to get the ith sample from the dataset. Apply the appropriate transformations.\n",
        "  \"\"\"\n",
        "  def __getitem__(self, index):\n",
        "    list_ = ast.literal_eval(self.events[index]) # Convert string literal to list\n",
        "    t, x, y, p = [], [], [], []\n",
        "    for e in list_:\n",
        "      t.append(e[0] * 1e6) # Convert to microseconds\n",
        "      x.append(e[1])\n",
        "      y.append(e[2])\n",
        "      p.append(e[3])\n",
        "    structured_events = tonic.io.make_structured_array(x, y, t, p) # Ordering is xytp now\n",
        "    transformed_frames = self.frame_transform(structured_events)\n",
        "    vel_xyz = []\n",
        "    vel_x = self.target.loc[index][0]\n",
        "    vel_xyz.append(vel_x)\n",
        "    vel_y = self.target.loc[index][1]\n",
        "    vel_xyz.append(vel_y)\n",
        "    vel_z = self.target.loc[index][2]\n",
        "    vel_xyz.append(vel_z)\n",
        "\n",
        "    frames_tensor = torch.tensor(transformed_frames)\n",
        "    vel_tensor = torch.tensor(vel_xyz, dtype = torch.float32)\n",
        "    return frames_tensor, vel_tensor\n",
        "\n",
        "  \"\"\"\n",
        "      Returns the size of the dataset.\n",
        "  \"\"\"\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "class PadMultiOutputTensor:\n",
        "  def __init__(self, batch_first: bool = False):\n",
        "    self.batch_first = batch_first\n",
        "\n",
        "  def __call__(self, batch):\n",
        "    samples_output = []\n",
        "    targets_output = []\n",
        "\n",
        "    max_length = max([sample.shape[0] for sample, target in batch])\n",
        "    for sample, target in batch:\n",
        "      if isinstance(sample, torch.Tensor):\n",
        "        sample = torch.tensor(sample)\n",
        "        samples_output.append(\n",
        "            torch.cat((sample,\n",
        "                       torch.zeros(max_length - sample.shape[0], *sample.shape[1:]),)))\n",
        "        targets_output.append(target)\n",
        "        \n",
        "    return (torch.stack(samples_output, 0 if self.batch_first else 1),\n",
        "            torch.stack(targets_output),)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NWgKCbuQKg1i"
      },
      "outputs": [],
      "source": [
        "# Create PyTorch dataset objects\n",
        "train_dataset = SyntheticRecording(train_df) \n",
        "val_dataset = SyntheticRecording(validation_df)\n",
        "test_dataset = SyntheticRecording(test_df)\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_loader = DataLoader(train_dataset, batch_size = 1,\n",
        "                          collate_fn = PadMultiOutputTensor())\n",
        "val_loader = DataLoader(val_dataset, batch_size = 1,\n",
        "                        collate_fn = PadMultiOutputTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1,\n",
        "                         collate_fn = PadMultiOutputTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mxNHz3asLecu"
      },
      "outputs": [],
      "source": [
        "class MultiOutputSNN(nn.Module):\n",
        "  def __init__(self, beta, spike_grad):\n",
        "    super(MultiOutputSNN, self).__init__()\n",
        "    self.beta = beta\n",
        "    self.spike_grad = spike_grad\n",
        "\n",
        "    # Initialize the layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 8, kernel_size = 5)\n",
        "    self.lif1 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.lif2 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.lif3 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5)\n",
        "    self.lif4 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.lif5 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.lif6 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.flat = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features = 16 * 267 * 477, out_features = 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    mem1 = self.lif1.init_leaky()\n",
        "    mem2 = self.lif2.init_leaky()\n",
        "    mem3 = self.lif3.init_leaky()\n",
        "    mem4 = self.lif4.init_leaky()\n",
        "    mem5 = self.lif5.init_leaky()\n",
        "    mem6 = self.lif6.init_leaky()\n",
        "\n",
        "    vel_xyz = None\n",
        "\n",
        "    for step in range(x.size(0)):\n",
        "      res = F.max_pool2d(self.conv1(x[step]), (2, 2))\n",
        "      spk1, mem1 = self.lif1(res, mem1)\n",
        "      spk2, mem2 = self.lif2(spk1, mem2)\n",
        "      spk3, mem3 = self.lif3(spk2, mem3)\n",
        "      res2 = F.max_pool2d(self.conv2(spk3), (2, 2))\n",
        "      spk4, mem4 = self.lif4(res2, mem4)\n",
        "      spk5, mem5 = self.lif5(spk4, mem5)\n",
        "      spk6, mem6 = self.lif4(spk5, mem6)\n",
        "      flat = self.flat(spk6)\n",
        "      vel_xyz = self.fc1(flat)\n",
        "      \n",
        "    return vel_xyz\n",
        "\n",
        "class MultiOutputSCNN816(nn.Module):\n",
        "  def __init__(self, alpha, beta, spike_grad):\n",
        "    super(MultiOutputSCNN816, self).__init__()\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.spike_grad = spike_grad\n",
        "\n",
        "    # Initialize the layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 8, kernel_size = 5)\n",
        "    self.lif1 = snn.Synaptic(alpha = self.alpha, beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 5)\n",
        "    self.lif2 = snn.Synaptic(alpha = self.alpha, beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.flat = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features = 16 * 267 * 477, out_features = 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    syn1, mem1 = self.lif1.init_synaptic()\n",
        "    syn2, mem2 = self.lif2.init_synaptic()\n",
        "\n",
        "    vel_xyz = None\n",
        "\n",
        "    for step in range(x.size(0)):\n",
        "      res = F.max_pool2d(self.conv1(x[step]), (2, 2))\n",
        "      spk1, syn1, mem1 = self.lif1(res, syn1, mem1)\n",
        "      res2 = F.max_pool2d(self.conv2(spk1), (2, 2))\n",
        "      spk2, syn2, mem2 = self.lif2(res2, syn2, mem2)\n",
        "      flat = self.flat(spk2)\n",
        "      vel_xyz = self.fc1(flat)\n",
        "      \n",
        "    return vel_xyz\n",
        "\n",
        "class MultiOutputSCNN1232(nn.Module):\n",
        "  def __init__(self, beta, spike_grad):\n",
        "    super(MultiOutputSCNN1232, self).__init__()\n",
        "    self.beta = beta\n",
        "    self.spike_grad = spike_grad\n",
        "\n",
        "    # Initialize the layers\n",
        "    self.conv1 = nn.Conv2d(in_channels = 2, out_channels = 12, kernel_size = 5)\n",
        "    self.lif1 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 12, out_channels = 32, kernel_size = 5)\n",
        "    self.lif2 = snn.Leaky(beta = self.beta, spike_grad = self.spike_grad)\n",
        "    self.flat = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(in_features = 32 * 267 * 477, out_features = 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    mem1 = self.lif1.init_leaky()\n",
        "    mem2 = self.lif2.init_leaky()\n",
        "\n",
        "    vel_xyz = None\n",
        "\n",
        "    for step in range(x.size(0)):\n",
        "      res = F.max_pool2d(self.conv1(x[step]), (2, 2))\n",
        "      spk1, mem1 = self.lif1(res, mem1)\n",
        "      res2 = F.max_pool2d(self.conv2(spk1), (2, 2))\n",
        "      spk2, mem2 = self.lif2(res2, mem2)\n",
        "      flat = self.flat(spk2)\n",
        "      vel_xyz = self.fc1(flat)\n",
        "      \n",
        "    return vel_xyz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zjheWiCaCbfj"
      },
      "outputs": [],
      "source": [
        "# Neuron and simulation parameters\n",
        "spike_grad = surrogate.fast_sigmoid(slope = 75)\n",
        "beta = 0.5\n",
        "alpha = 0.6\n",
        "torch.cuda.empty_cache()\n",
        "net = MultiOutputSCNN816(beta, alpha, spike_grad).cuda()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr = 1e-8)\n",
        "loss_fn = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuntJBHL6xhe",
        "outputId": "2a5b19da-c014-4e63-8fd5-742a62d77d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
        }
      ],
      "source": [
        "def training_loop(net, train_loader, val_loader, optimizer, loss_fn):\n",
        "  num_epochs = 1\n",
        "  loss_l1 = nn.L1Loss()\n",
        "\n",
        "  # Store loss history for future plotting\n",
        "  loss_history, test_loss_history  = [], []\n",
        "  loss_history_mae, test_loss_history_mae = [], []\n",
        "  loss, test_loss = 0, 0\n",
        "  history = dict()\n",
        "  history_val = dict()\n",
        "  counter = 0\n",
        "  val_counter = 0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    batch = iter(train_loader)\n",
        "    for data, targets in batch: # Training loop\n",
        "      optimizer.zero_grad() # Clear gradients for next train\n",
        "\n",
        "      data = data.cuda()\n",
        "      targets = targets.cuda()\n",
        "      net.train() # Forward pass\n",
        "      prediction = net(data) # Predictions\n",
        "\n",
        "      loss = torch.sqrt(loss_fn(prediction, targets))\n",
        "      loss_mae = loss_l1(prediction, targets)\n",
        "      loss_history.append(loss.item())\n",
        "      loss_history_mae.append(loss_mae.item())\n",
        "\n",
        "      # Gradient calculation and weight update\n",
        "      loss.backward() # Backpropagation, compute gradients\n",
        "      optimizer.step() # Performs the update (apply gradients)\n",
        "   \n",
        "      if counter % 10 == 0: # Print every 10 results\n",
        "        print(f\"Training Iteration {counter}: Training RMSE: {loss.item()}, Training MAE: {loss_mae.item()}\")\n",
        "      counter += 1\n",
        "\n",
        "    with torch.no_grad(): # Test loop - do not track history for backpropagation\n",
        "      net.eval() # Test forward pass\n",
        "      test_batch = iter(val_loader)\n",
        "      for test_data, test_targets in test_batch:\n",
        "        test_data = test_data.cuda()\n",
        "        test_targets = test_targets.cuda()\n",
        "        test_pred = net(test_data) # Predictions\n",
        "\n",
        "        test_loss = torch.sqrt(loss_fn(test_pred, test_targets))\n",
        "        test_loss_mae = loss_l1(test_pred, test_targets)\n",
        "        test_loss_history.append(test_loss.item())\n",
        "        test_loss_history_mae.append(test_loss_mae.item())\n",
        "\n",
        "        if val_counter % 10 == 0:\n",
        "          print(f\"Validation Iteration {val_counter}: Validation RMSE: {test_loss.item()}, Validation MAE: {test_loss_mae.item()}\")\n",
        "        val_counter += 1\n",
        "\n",
        "  history['Training RMSE'] = loss_history\n",
        "  history['Training MAE'] = loss_history_mae\n",
        "  history_val['Validation RMSE'] = test_loss_history\n",
        "  history_val['Validation MAE'] = test_loss_history_mae\n",
        "  torch.save(net.state_dict(), SRC + 'results/model2.pt')\n",
        "  return history, history_val\n",
        "\n",
        "history, history_val = training_loop(net, train_loader, val_loader, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NG4OrgPBtFb"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame.from_dict(history)\n",
        "history_val_df = pd.DataFrame.from_dict(history_val)\n",
        "history_df.to_csv(SRC + 'results/history_model2.csv')\n",
        "history_val_df.to_csv(SRC + 'results/history_val_model2.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
